{"id": "2602.09112", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09112", "abs": "https://arxiv.org/abs/2602.09112", "authors": ["Russ Webb", "Jason Ramapuram"], "title": "A Small-Scale System for Autoregressive Program Synthesis Enabling Controlled Experimentation", "comment": null, "summary": "What research can be pursued with small models trained to complete true programs? Typically, researchers study program synthesis via large language models (LLMs) which introduce issues such as knowing what is in or out of distribution, understanding fine-tuning effects, understanding the effects of tokenization, and higher demand on compute and storage to carry out experiments. We present a system called Cadmus which includes an integer virtual machine (VM), a dataset composed of true programs of diverse tasks, and an autoregressive transformer model that is trained for under \\$200 of compute cost. The system can be used to study program completion, out-of-distribution representations, inductive reasoning, and instruction following in a setting where researchers have effective and affordable fine-grained control of the training distribution and the ability to inspect and instrument models. Smaller models working on complex reasoning tasks enable instrumentation and investigations that may be prohibitively expensive on larger models. To demonstrate that these tasks are complex enough to be of interest, we show that these Cadmus models outperform GPT-5 (by achieving 100\\% accuracy while GPT-5 has 95\\% accuracy) even on a simple task of completing correct, integer arithmetic programs in our domain-specific language (DSL) while providing transparency into the dataset's relationship to the problem. We also show that GPT-5 brings unknown priors into its reasoning process when solving the same tasks, demonstrating a confounding factor that prevents the use of large-scale LLMs for some investigations where the training set relationship to the task needs to be fully understood."}
{"id": "2602.09121", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09121", "abs": "https://arxiv.org/abs/2602.09121", "authors": ["RÃ©mi Grzeczkowicz", "Eric Soriano", "Ali Janati", "Miyu Zhang", "Gerard Comas-Quiles", "Victor Carballo Araruna", "Aneesh Jonelagadda"], "title": "Uncertainty-Aware Multimodal Emotion Recognition through Dirichlet Parameterization", "comment": "8 pages, 3 figures", "summary": "In this work, we present a lightweight and privacy-preserving Multimodal Emotion Recognition (MER) framework designed for deployment on edge devices. To demonstrate framework's versatility, our implementation uses three modalities - speech, text and facial imagery. However, the system is fully modular, and can be extended to support other modalities or tasks. Each modality is processed through a dedicated backbone optimized for inference efficiency: Emotion2Vec for speech, a ResNet-based model for facial expressions, and DistilRoBERTa for text. To reconcile uncertainty across modalities, we introduce a model- and task-agnostic fusion mechanism grounded in Dempster-Shafer theory and Dirichlet evidence. Operating directly on model logits, this approach captures predictive uncertainty without requiring additional training or joint distribution estimation, making it broadly applicable beyond emotion recognition. Validation on five benchmark datasets (eNTERFACE05, MEAD, MELD, RAVDESS and CREMA-D) show that our method achieves competitive accuracy while remaining computationally efficient and robust to ambiguous or missing inputs. Overall, the proposed framework emphasizes modularity, scalability, and real-world feasibility, paving the way toward uncertainty-aware multimodal systems for healthcare, human-computer interaction, and other emotion-informed applications."}
{"id": "2602.09138", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.09138", "abs": "https://arxiv.org/abs/2602.09138", "authors": ["Haitao Jiang", "Lin Ge", "Hengrui Cai", "Rui Song"], "title": "PABU: Progress-Aware Belief Update for Efficient LLM Agents", "comment": null, "summary": "Large Language Model (LLM) agents commonly condition actions on full action-observation histories, which introduce task-irrelevant information that easily leads to redundant actions and higher inference cost. We propose Progress-Aware Belief Update (PABU), a belief-state framework that compactly represents an agent's state by explicitly modeling task progress and selectively retaining past actions and observations. At each step, the agent predicts its relative progress since the previous round and decides whether the newly encountered interaction should be stored, conditioning future decisions only on the retained subset. Across eight environments in the AgentGym benchmark, and using identical training trajectories, PABU achieves an 81.0% task completion rate, outperforming previous State of the art (SoTA) models with full-history belief by 23.9%. Additionally, PABU's progress-oriented action selection improves efficiency, reducing the average number of interaction steps to 9.5, corresponding to a 26.9% reduction. Ablation studies show that both explicit progress prediction and selective retention are necessary for robust belief learning and performance gains."}
{"id": "2602.09159", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.09159", "abs": "https://arxiv.org/abs/2602.09159", "authors": ["Yichen Wu", "Yujin Oh", "Sangjoon Park", "Kailong Fan", "Dania Daye", "Hana Farzaneh", "Xiang Li", "Raul Uppot", "Quanzheng Li"], "title": "CoMMa: Contribution-Aware Medical Multi-Agents From A Game-Theoretic Perspective", "comment": "9 pages, 3 figures", "summary": "Recent multi-agent frameworks have broadened the ability to tackle oncology decision support tasks that require reasoning over dynamic, heterogeneous patient data. We propose Contribution-Aware Medical Multi-Agents (CoMMa), a decentralized LLM-agent framework in which specialists operate on partitioned evidence and coordinate through a game-theoretic objective for robust decision-making. In contrast to most agent architectures relying on stochastic narrative-based reasoning, CoMMa utilizes deterministic embedding projections to approximate contribution-aware credit assignment. This yields explicit evidence attribution by estimating each agent's marginal utility, producing interpretable and mathematically grounded decision pathways with improved stability. Evaluated on diverse oncology benchmarks, including a real-world multidisciplinary tumor board dataset, CoMMa achieves higher accuracy and more stable performance than data-centralized and role-based multi-agents baselines."}
{"id": "2602.09386", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.09386", "abs": "https://arxiv.org/abs/2602.09386", "authors": ["Yukun Zhang", "Si Dong", "Xu Wang", "Bo Chen", "Qinglin Jia", "Shengzhe Wang", "Jinlong Jiao", "Runhan Li", "Jiaqing Liu", "Chaoyi Ma", "Ruiming Tang", "Guorui Zhou", "Han Li", "Kun Gai"], "title": "SMES: Towards Scalable Multi-Task Recommendation via Expert Sparsity", "comment": null, "summary": "Industrial recommender systems typically rely on multi-task learning to estimate diverse user feedback signals and aggregate them for ranking. Recent advances in model scaling have shown promising gains in recommendation. However, naively increasing model capacity imposes prohibitive online inference costs and often yields diminishing returns for sparse tasks with skewed label distributions. This mismatch between uniform parameter scaling and heterogeneous task capacity demands poses a fundamental challenge for scalable multi-task recommendation. In this work, we investigate parameter sparsification as a principled scaling paradigm and identify two critical obstacles when applying sparse Mixture-of-Experts (MoE) to multi-task recommendation: exploded expert activation that undermines instance-level sparsity and expert load skew caused by independent task-wise routing. To address these challenges, we propose SMES, a scalable sparse MoE framework with progressive expert routing. SMES decomposes expert activation into a task-shared expert subset jointly selected across tasks and task-adaptive private experts, explicitly bounding per-instance expert execution while preserving task-specific capacity. In addition, SMES introduces a global multi-gate load-balancing regularizer that stabilizes training by regulating aggregated expert utilization across all tasks. SMES has been deployed in Kuaishou large-scale short-video services, supporting over 400 million daily active users. Extensive online experiments demonstrate stable improvements, with GAUC gain of 0.29% and a 0.31% uplift in user watch time."}
{"id": "2602.09216", "categories": ["cs.HC", "cs.CV", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.09216", "abs": "https://arxiv.org/abs/2602.09216", "authors": ["Varchita Lalwani", "Utkarsh Agarwal", "Michael Saugstad", "Manish Kumar", "Jon E. Froehlich", "Anupam Sobti"], "title": "Towards Human-AI Accessibility Mapping in India: VLM-Guided Annotations and POI-Centric Analysis in Chandigarh", "comment": "Accepted at the First Workshop on AI for Urban Planning (AI4Up) at AAAI 2025", "summary": "Project Sidewalk is a web-based platform that enables crowdsourcing accessibility of sidewalks at city-scale by virtually walking through city streets using Google Street View. The tool has been used in 40 cities across the world, including the US, Mexico, Chile, and Europe. In this paper, we describe adaptation efforts to enable deployment in Chandigarh, India, including modifying annotation types, provided examples, and integrating VLM-based mission guidance, which adapts instructions based on a street scene and metadata analysis. Our evaluation with 3 annotators indicates the utility of AI-mission guidance with an average score of 4.66. Using this adapted Project Sidewalk tool, we conduct a Points of Interest (POI)-centric accessibility analysis for three sectors in Chandigarh with very different land uses, residential, commercial and institutional covering about 40 km of sidewalks. Across 40 km of roads audited in three sectors and around 230 POIs, we identified 1,644 of 2,913 locations where infrastructure improvements could enhance accessibility."}
{"id": "2602.09289", "categories": ["cs.SI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.09289", "abs": "https://arxiv.org/abs/2602.09289", "authors": ["Christine de Kock", "Eduard Hovy"], "title": "Triggered: A Statistical Analysis of Environmental Influences on Extremist Groups", "comment": null, "summary": "Online extremist communities operate within a wider information ecosystem shaped by real-world events, news coverage, and cross-community interaction. We adopt a systems perspective to examine these influences using seven years of data from two ideologically distinct extremist forums (Stormfront and Incels) and a mainstream reference community (r/News). We ask three questions: how extremist violence impacts community behaviour; whether news coverage of political entities predicts shifts in conversation dynamics; and whether linguistic diffusion occurs between mainstream and extremist spaces and across extremist ideologies. Methodologically, we combine counterfactual synthesis to estimate event-level impacts with vector autoregression and Granger causality analyses to model ongoing relationships among news signals, behavioural outcomes, and cross-community language change. Across analyses, our results indicate that Stormfront and r/News appear to be more reactive to external stimuli, while Incels demonstrates less cross-community linguistic influence and less responsiveness to news and violent events. These findings underscore that extremist communities are not homogeneous, but differ in how tightly they are coupled to the surrounding information ecosystem."}
{"id": "2602.09163", "categories": ["cs.AI", "cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.09163", "abs": "https://arxiv.org/abs/2602.09163", "authors": ["Xingjian Zhang", "Sophia Moylan", "Ziyang Xiong", "Qiaozhu Mei", "Yichen Luo", "Jiaqi W. Ma"], "title": "FlyAOC: Evaluating Agentic Ontology Curation of Drosophila Scientific Knowledge Bases", "comment": null, "summary": "Scientific knowledge bases accelerate discovery by curating findings from primary literature into structured, queryable formats for both human researchers and emerging AI systems. Maintaining these resources requires expert curators to search relevant papers, reconcile evidence across documents, and produce ontology-grounded annotations - a workflow that existing benchmarks, focused on isolated subtasks like named entity recognition or relation extraction, do not capture. We present FlyBench to evaluate AI agents on end-to-end agentic ontology curation from scientific literature. Given only a gene symbol, agents must search and read from a corpus of 16,898 full-text papers to produce structured annotations: Gene Ontology terms describing function, expression patterns, and historical synonyms linking decades of nomenclature. The benchmark includes 7,397 expert-curated annotations across 100 genes drawn from FlyBase, the Drosophila (fruit fly) knowledge base. We evaluate four baseline agent architectures: memorization, fixed pipeline, single-agent, and multi-agent. We find that architectural choices significantly impact performance, with multi-agent designs outperforming simpler alternatives, yet scaling backbone models yields diminishing returns. All baselines leave substantial room for improvement. Our analysis surfaces several findings to guide future development; for example, agents primarily use retrieval to confirm parametric knowledge rather than discover new information. We hope FlyBench will drive progress on retrieval-augmented scientific reasoning, a capability with broad applications across scientific domains."}
{"id": "2602.09387", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.09387", "abs": "https://arxiv.org/abs/2602.09387", "authors": ["Fangye Wang", "Guowei Yang", "Xiaojiang Zhou", "Song Yang", "Pengjie Wang"], "title": "Query-Mixed Interest Extraction and Heterogeneous Interaction: A Scalable CTR Model for Industrial Recommender Systems", "comment": null, "summary": "Learning effective feature interactions is central to modern recommender systems, yet remains challenging in industrial settings due to sparse multi-field inputs and ultra-long user behavior sequences. While recent scaling efforts have improved model capacity, they often fail to construct both context-aware and context-independent user intent from the long-term and real-time behavior sequence. Meanwhile, recent work also suffers from inefficient and homogeneous interaction mechanisms, leading to suboptimal prediction performance. To address these limitations, we propose HeMix, a scalable ranking model that unifies adaptive sequence tokenization and heterogeneous interaction structure. Specifically, HeMix introduces a Query-Mixed Interest Extraction module that jointly models context-aware and context-independent user interests via dynamic and fixed queries over global and real-time behavior sequences. For interaction, we replace self-attention with the HeteroMixer block, enabling efficient, multi-granularity cross-feature interactions that adopt the multi-head token fusion, heterogeneous interaction and group-aligned reconstruction pipelines. HeMix demonstrates favorable scaling behavior, driven by the HeteroMixer block, where increasing model scale via parameter expansion leads to steady improvements in recommendation accuracy. Experiments on industrial-scale datasets show that HeMix scales effectively and consistently outperforms strong baselines. Most importantly, HeMix has been deployed on the AMAP platform, delivering significant online gains: +0.61% GMV, +2.32% PV_CTR, and +0.81% UV_CVR."}
{"id": "2602.09236", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.09236", "abs": "https://arxiv.org/abs/2602.09236", "authors": ["Yuanzhe Deng", "Shutong Zhang", "Kathy Cheng", "Alison Olechowski", "Shurui Zhou"], "title": "Untangling the Timeline: Challenges and Opportunities in Supporting Version Control in Modern Computer-Aided Design", "comment": "20 pages, 7 figures, to be published in the Proceedings of the 2026 CHI Conference on Human Factors in Computing Systems", "summary": "Version control is critical in mechanical computer-aided design (CAD) to enable traceability, manage product variation, and support collaboration. Yet, its implementation in modern CAD software as an essential information infrastructure for product development remains plagued by issues due to the complexity and interdependence of design data. This paper presents a systematic review of user-reported challenges with version control in modern CAD tools. Analyzing 170 online forum threads, we identify recurring socio-technical issues that span the management, continuity, scope, and distribution of versions. Our findings inform a broader reflection on how version control should be designed and improved for CAD and motivate opportunities for tools and mechanisms that better support articulation work, facilitate cross-boundary collaboration, and operate with infrastructural reflexivity. This study offers actionable insights for CAD software providers and highlights opportunities for researchers to rethink version control."}
{"id": "2602.09543", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2602.09543", "abs": "https://arxiv.org/abs/2602.09543", "authors": ["Hana Kapadia", "Arun Kumar Rajasekaran"], "title": "Shifting landscape of disability and development in India: Analysis from historical trends to future predictions 2001-2031", "comment": null, "summary": "This study delves into the causes and trends of disability-related health burdens across Indian states. Through multiple Disability-Adjusted Life Years (DALY) types (covering communicable diseases, noncommunicable diseases, and injuries), gender disparities, and Human Development Index (HDI) values, these disability trends were evaluated. The data for this study was compiled from censuses, health research organisations, and data centres, among various other sources. We built regression models and used them to analyze trends across past decades and make projections for 2031. Our regression results show a strong inverse relationship between communicable disease DALYs and HDI. In other words, ongoing improvements in development and infrastructure significantly reduced communicable disease DALYs. In contrast, noncommunicable DALYs did not decrease despite rising HDI. And lastly, injury DALYs showed moderate declines with higher HDI, which reflects improvements in healthcare and safety systems. Gender analysis showed male overrepresentation among people with disabilities. These results from our study support that there is a need to shift public health focus toward chronic diseases and address gender disparities in disability outcomes."}
{"id": "2602.09286", "categories": ["cs.AI", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.09286", "abs": "https://arxiv.org/abs/2602.09286", "authors": ["Hanjing Shi", "Dominic DiFranzo"], "title": "Human Control Is the Anchor, Not the Answer: Early Divergence of Oversight in Agentic AI Communities", "comment": null, "summary": "Oversight for agentic AI is often discussed as a single goal (\"human control\"), yet early adoption may produce role-specific expectations. We present a comparative analysis of two newly active Reddit communities in Jan--Feb 2026 that reflect different socio-technical roles: r/OpenClaw (deployment and operations) and r/Moltbook (agent-centered social interaction). We conceptualize this period as an early-stage crystallization phase, where oversight expectations form before norms reach equilibrium.\n  Using topic modeling in a shared comparison space, a coarse-grained oversight-theme abstraction, engagement-weighted salience, and divergence tests, we show the communities are strongly separable (JSD =0.418, cosine =0.372, permutation $p=0.0005$). Across both communities, \"human control\" is an anchor term, but its operational meaning diverges: r/OpenClaw} emphasizes execution guardrails and recovery (action-risk), while r/Moltbook} emphasizes identity, legitimacy, and accountability in public interaction (meaning-risk). The resulting distinction offers a portable lens for designing and evaluating oversight mechanisms that match agent role, rather than applying one-size-fits-all control policies."}
{"id": "2602.09401", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.09401", "abs": "https://arxiv.org/abs/2602.09401", "authors": ["Ruochen Yang", "Yueyang Liu", "Zijie Zhuang", "Changxin Lao", "Yuhui Zhang", "Jiangxia Cao", "Jia Xu", "Xiang Chen", "Haoke Xiao", "Xiangyu Wu", "Xiaoyou Zhou", "Xiao Lv", "Shuang Yang", "Tingwen Liu", "Zhaojie Liu", "Han Li", "Kun Gai"], "title": "SARM: LLM-Augmented Semantic Anchor for End-to-End Live-Streaming Ranking", "comment": null, "summary": "Large-scale live-streaming recommendation requires precise modeling of non-stationary content semantics under strict real-time serving constraints. In industrial deployment, two common approaches exhibit fundamental limitations: discrete semantic abstractions sacrifice descriptive precision through clustering, while dense multimodal embeddings are extracted independently and remain weakly aligned with ranking optimization, limiting fine-grained content-aware ranking. To address these limitations, we propose \\textbf{SARM}, an end-to-end ranking architecture that integrates natural-language semantic anchors directly into ranking optimization, enabling fine-grained author representations conditioned on multimodal content. Each semantic anchor is represented as learnable text tokens jointly optimized with ranking features, allowing the model to adapt content descriptions to ranking objectives. A lightweight dual-token gated design captures domain-specific live-streaming semantics, while an asymmetric deployment strategy preserves low-latency online training and serving. Extensive offline evaluation and large-scale A/B tests show consistent improvements over production baselines. SARM is fully deployed and serves over 400 million users daily."}
{"id": "2602.09254", "categories": ["cs.HC", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.09254", "abs": "https://arxiv.org/abs/2602.09254", "authors": ["Shijing He", "Xuchen Wang", "Yaxiong Lei", "Chi Zhang", "Ruba Abu-Salma", "Jose Such"], "title": "Investigating Bystander Privacy in Chinese Smart Home Apps", "comment": "Paper accepted for presentation at CHI 2026", "summary": "Bystander privacy in smart homes has been widely studied in Western contexts, yet it remains underexplored in non-Western countries such as China. In this study, we analyze 49 Chinese smart home apps using a mixed-methods approach, including privacy policy review, UX/UI evaluation, and assessment of Apple App Store privacy labels. While most apps nominally comply with national regulations, we identify significant gaps between written policies and actual implementation. Our traceability analysis highlights inconsistencies in data controls and a lack of transparency in data-sharing practices. Crucially, bystander privacy -- particularly for visitors and non-user individuals -- is largely absent from both policy documents and interface design. Additionally, discrepancies between privacy labels and actual data practices threaten user trust and undermine informed consent. We provide design recommendations to strengthen bystander protections, improve privacy-oriented UI transparency, and enhance the credibility of privacy labels, supporting the development of inclusive smart home ecosystems in non-Western contexts."}
{"id": "2602.09618", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2602.09618", "abs": "https://arxiv.org/abs/2602.09618", "authors": ["Caimeng Wang", "Li Chong", "Dongxu Liu", "Xu Min", "Jianhui Bu"], "title": "UniShare: A Unified Framework for Joint Video and Receiver Recommendation in Social Sharing", "comment": null, "summary": "Sharing behavior on short-video platforms constitutes a complex ternary interaction among the user (sharer), the video (content), and the receiver. Traditional industrial solutions often decouple this into two independent tasks: video recommendation (predicting share probability) and receiver recommendation (predicting whom to share with), leading to suboptimal performance due to isolated modeling and inadequate information utilization. To address this, we propose UniShare, a novel unified framework for joint sharing prediction on both video and receiver recommendation. UniShare models the share probability through an enhanced representation learning module that incorporates pre-trained GNN and multi-modal embeddings, alongside explicit bilateral interest and relationship matching. A key innovation is our joint training paradigm, which leverages signals from both tasks to mutually enhance each other, mitigating data sparsity and improving bilateral satisfaction. We also introduce K-Share, a large-scale real-world dataset constructed from Kuaishou platform logs to support research in this domain. Extensive offline experiments demonstrate that UniShare significantly outperforms strong baselines on both tasks. Furthermore, online A/B testing on the Kuaishou platform confirms its effectiveness, achieving significant improvements in key metrics including the number of shares (+1.95%) and receiver reply rate (+0.482%)."}
{"id": "2602.09340", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09340", "abs": "https://arxiv.org/abs/2602.09340", "authors": ["Yang Ba", "Mohammad Sadeq Abolhasani", "Michelle V Mancenido", "Rong Pan"], "title": "Measuring Dataset Diversity from a Geometric Perspective", "comment": null, "summary": "Diversity can be broadly defined as the presence of meaningful variation across elements, which can be viewed from multiple perspectives, including statistical variation and geometric structural richness in the dataset. Existing diversity metrics, such as feature-space dispersion and metric-space magnitude, primarily capture distributional variation or entropy, while largely neglecting the geometric structure of datasets. To address this gap, we introduce a framework based on topological data analysis (TDA) and persistence landscapes (PLs) to extract and quantify geometric features from data. This approach provides a theoretically grounded means of measuring diversity beyond entropy, capturing the rich geometric and structural properties of datasets. Through extensive experiments across diverse modalities, we demonstrate that our proposed PLs-based diversity metric (PLDiv) is powerful, reliable, and interpretable, directly linking data diversity to its underlying geometry and offering a foundational tool for dataset construction, augmentation, and evaluation."}
{"id": "2602.09445", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.09445", "abs": "https://arxiv.org/abs/2602.09445", "authors": ["Sunwoo Kim", "Hyunjin Hwang", "Kijung Shin"], "title": "Personalized Parameter-Efficient Fine-Tuning of Foundation Models for Multimodal Recommendation", "comment": "To be published at The Web Conference 2026 (WWW 2026)", "summary": "In recent years, substantial research has integrated multimodal item metadata into recommender systems, often by using pre-trained multimodal foundation models to encode such data. Since these models are not originally trained for recommendation tasks, recent works efficiently adapt them via parameter-efficient fine-tuning (PEFT). However, even with PEFT, item embeddings from multimodal foundation models remain user-blind: item embeddings are not conditioned on user interests, despite the fact that users with diverse interests attend to different item aspects. To address this limitation, we propose PerPEFT, a personalized PEFT strategy for multimodal recommendation. Specifically, PerPEFT groups users by interest and assigns a distinct PEFT module to each group, enabling each module to capture the fine-grained item aspects most predictive of that group`s purchase decisions. We further introduce a specialized training technique that strengthens this user-group conditioning. Notably, PerPEFT is PEFT-agnostic and can be paired with any PEFT method applicable to multimodal foundation models. Through extensive experiments, we show that (1) PerPEFT outperforms the strongest baseline by up to 15.3% (NDCG@20) and (2) delivers consistent gains across diverse PEFT variants. It is noteworthy that, even with personalization, PEFT remains lightweight, adding only 1.3% of the parameter count of the foundation model. We provide our code and datasets at https://github.com/kswoo97/PerPEFT."}
{"id": "2602.09256", "categories": ["cs.HC", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.09256", "abs": "https://arxiv.org/abs/2602.09256", "authors": ["Shijing He", "Chenkai Ma", "Chi Zhang", "Adam Jenkins", "Ruba Abu-Salma", "Jose Such"], "title": "\"Create an environment that protects women, rather than selling anxiety!\": Participatory Threat Modeling with Chinese Young Women Living Alone", "comment": "Paper accepted for presentation at CHI 2026", "summary": "As more young women in China live alone, they navigate entangled privacy, security, and safety (PSS) risks across smart homes, online platforms, and public infrastructures. Drawing on six participatory threat modeling (PTM) workshops (n = 33), we present a human-centered threat model that illustrates how digitally facilitated physical violence, digital harassment and scams, and pervasive surveillance by individuals, companies, and the state are interconnected and mutually reinforcing. We also document four mitigation strategies employed by participants: smart home device configurations, boundary management, sociocultural practices, and social media tactics--each of which can introduce new vulnerabilities and emotional burdens. Based on these insights, we developed a digital PSS guidebook for young women living alone (YWLA) in China. We further propose actionable design implications for smart home devices and social media platforms, along with policy and legal recommendations and directions for educational interventions."}
{"id": "2602.09997", "categories": ["cs.SI", "q-bio.NC", "q-bio.PE"], "pdf": "https://arxiv.org/pdf/2602.09997", "abs": "https://arxiv.org/abs/2602.09997", "authors": ["Lucas Gautheron", "Raja Marjieh", "Dalton C. Conley", "Seth Frey", "Hannah Rubin", "Mike D. Schneider", "Ofer Tchernichovski", "Nori Jacoby"], "title": "Popularity Feedback Constrains Innovation in Cultural Markets", "comment": null, "summary": "Real-world creative processes ranging from art to science rely on social feedback-loops between selection and creation. Yet, the effects of popularity feedback on collective creativity remain poorly understood. We investigate how popularity ratings influence cultural dynamics in a large-scale online experiment where participants ($N = 1\\,008$) iteratively \\textit{select} images from evolving markets and \\textit{produce} their own modifications. Results show that exposing the popularity of images reduces cultural diversity and slows innovation, delaying aesthetic improvements. These findings are mediated by alterations of both selection and creation. During selection, popularity information triggers cumulative advantage, with participants preferentially building upon popular images, reducing diversity. During creation, participants make less disruptive changes, and are more likely to expand existing visual patterns. Feedback loops in cultural markets thus not only shape selection, but also, directly or indirectly, the form and direction of cultural innovation."}
{"id": "2602.09341", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09341", "abs": "https://arxiv.org/abs/2602.09341", "authors": ["Wei Yang", "Shixuan Li", "Heng Ping", "Peiyu Zhang", "Paul Bogdan", "Jesse Thomason"], "title": "Auditing Multi-Agent LLM Reasoning Trees Outperforms Majority Vote and LLM-as-Judge", "comment": null, "summary": "Multi-agent systems (MAS) can substantially extend the reasoning capacity of large language models (LLMs), yet most frameworks still aggregate agent outputs with majority voting. This heuristic discards the evidential structure of reasoning traces and is brittle under the confabulation consensus, where agents share correlated biases and converge on the same incorrect rationale. We introduce AgentAuditor, which replaces voting with a path search over a Reasoning Tree that explicitly represents agreements and divergences among agent traces. AgentAuditor resolves conflicts by comparing reasoning branches at critical divergence points, turning global adjudication into efficient, localized verification. We further propose Anti-Consensus Preference Optimization (ACPO), which trains the adjudicator on majority-failure cases and rewards evidence-based minority selections over popular errors. AgentAuditor is agnostic to MAS setting, and we find across 5 popular settings that it yields up to 5% absolute accuracy improvement over a majority vote, and up to 3% over using LLM-as-Judge."}
{"id": "2602.09448", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.09448", "abs": "https://arxiv.org/abs/2602.09448", "authors": ["Xincan Feng", "Noriki Nishida", "Yusuke Sakai", "Yuji Matsumoto"], "title": "The Wisdom of Many Queries: Complexity-Diversity Principle for Dense Retriever Training", "comment": "Under review", "summary": "Prior work reports conflicting results on query diversity in synthetic data generation for dense retrieval. We identify this conflict and design Q-D metrics to quantify diversity's impact, making the problem measurable. Through experiments on 4 benchmark types (31 datasets), we find query diversity especially benefits multi-hop retrieval. Deep analysis on multi-hop data reveals that diversity benefit correlates strongly with query complexity ($r$$\\geq$0.95, $p$$<$0.05 in 12/14 conditions), measured by content words (CW). We formalize this as the Complexity-Diversity Principle (CDP): query complexity determines optimal diversity. CDP provides actionable thresholds (CW$>$10: use diversity; CW$<$7: avoid it). Guided by CDP, we propose zero-shot multi-query synthesis for multi-hop tasks, achieving state-of-the-art performance."}
{"id": "2602.09296", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.09296", "abs": "https://arxiv.org/abs/2602.09296", "authors": ["Frederic Gmeiner", "John Thompson", "George Fitzmaurice", "Justin Matejka"], "title": "PointAloud: An Interaction Suite for AI-Supported Pointer-Centric Think-Aloud Computing", "comment": "Paper accepted to the 2026 CHI Conference on Human Factors in Computing Systems (CHI 2026)", "summary": "Think-Aloud Computing, a method for capturing users' verbalized thoughts during software tasks, allows eliciting rich contextual insights into evolving intentions, struggles, and decision-making processes of users in real-time. However, existing approaches face practical challenges: users often lack awareness of what is captured by the system, are not effectively encouraged to speak, and miss or are interrupted by system feedback. Additionally, thinking aloud should feel worthwhile for users due to the gained contextual AI assistance. To better support and harness Think-Aloud Computing, we introduce PointAloud, a suite of novel AI-driven pointer-centric interactions for in-the-moment verbalization encouragement, low-distraction system feedback, and contextually rich work process documentation alongside proactive AI assistance. Our user study with 12 participants provides insights into the value of pointer-centric think-aloud computing for work process documentation and human-AI co-creation. We conclude by discussing the broader implications of our findings and design considerations for pointer-centric and AI-supported Think-Aloud Computing workflows."}
{"id": "2602.10001", "categories": ["cs.SI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.10001", "abs": "https://arxiv.org/abs/2602.10001", "authors": ["Chenyi Li", "Raja Marjieh", "Haoyu Hu", "Mark Steyvers", "Katherine M. Collins", "Ilia Sucholutsky", "Nori Jacoby"], "title": "Human-AI Synergy Supports Collective Creative Search", "comment": null, "summary": "Generative AI is increasingly transforming creativity into a hybrid human-artificial process, but its impact on the quality and diversity of creative output remains unclear. We study collective creativity using a controlled word-guessing task that balances open-endedness with an objective measure of task performance. Participants attempt to infer a hidden target word, scored based on the semantic similarity of their guesses to the target, while also observing the best guess from previous players. We compare performance and outcome diversity across human-only, AI-only, and hybrid human-AI groups. Hybrid groups achieve the highest performance while preserving high diversity of guesses. Within hybrid groups, both humans and AI agents systematically adjust their strategies relative to single-agent conditions, suggesting higher-order interaction effects, whereby agents adapt to each other's presence. Although some performance benefits can be reproduced through collaboration between heterogeneous AI systems, human-AI collaboration remains superior, underscoring complementary roles in collective creativity."}
{"id": "2602.09343", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.09343", "abs": "https://arxiv.org/abs/2602.09343", "authors": ["Michail S. Alexiou", "J. Sukarno Mertoguno"], "title": "Not-in-Perspective: Towards Shielding Google's Perspective API Against Adversarial Negation Attacks", "comment": null, "summary": "The rise of cyberbullying in social media platforms involving toxic comments has escalated the need for effective ways to monitor and moderate online interactions. Existing solutions of automated toxicity detection systems, are based on a machine or deep learning algorithms. However, statistics-based solutions are generally prone to adversarial attacks that contain logic based modifications such as negation in phrases and sentences. In that regard, we present a set of formal reasoning-based methodologies that wrap around existing machine learning toxicity detection systems. Acting as both pre-processing and post-processing steps, our formal reasoning wrapper helps alleviating the negation attack problems and significantly improves the accuracy and efficacy of toxicity scoring. We evaluate different variations of our wrapper on multiple machine learning models against a negation adversarial dataset. Experimental results highlight the improvement of hybrid (formal reasoning and machine-learning) methods against various purely statistical solutions."}
{"id": "2602.09616", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09616", "abs": "https://arxiv.org/abs/2602.09616", "authors": ["Zeinab Sadat Taghavi", "Ali Modarressi", "Hinrich Schutze", "Andreas Marfurt"], "title": "With Argus Eyes: Assessing Retrieval Gaps via Uncertainty Scoring to Detect and Remedy Retrieval Blind Spots", "comment": "8 pages", "summary": "Reliable retrieval-augmented generation (RAG) systems depend fundamentally on the retriever's ability to find relevant information. We show that neural retrievers used in RAG systems have blind spots, which we define as the failure to retrieve entities that are relevant to the query, but have low similarity to the query embedding. We investigate the training-induced biases that cause such blind spot entities to be mapped to inaccessible parts of the embedding space, resulting in low retrievability. Using a large-scale dataset constructed from Wikidata relations and first paragraphs of Wikipedia, and our proposed Retrieval Probability Score (RPS), we show that blind spot risk in standard retrievers (e.g., CONTRIEVER, REASONIR) can be predicted pre-index from entity embedding geometry, avoiding expensive retrieval evaluations. To address these blind spots, we introduce ARGUS, a pipeline that enables the retrievability of high-risk (low-RPS) entities through targeted document augmentation from a knowledge base (KB), first paragraphs of Wikipedia, in our case. Extensive experiments on BRIGHT, IMPLIRET, and RAR-B show that ARGUS achieves consistent improvements across all evaluated retrievers (averaging +3.4 nDCG@5 and +4.5 nDCG@10 absolute points), with substantially larger gains in challenging subsets. These results establish that preemptively remedying blind spots is critical for building robust and trustworthy RAG systems (Code and Data)."}
{"id": "2602.09310", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.09310", "abs": "https://arxiv.org/abs/2602.09310", "authors": ["Ananya Gubbi Mohanbabu", "Rosiana Natalie", "Brandon Kim", "Anhong Guo", "Amy Pavel"], "title": "A11y-CUA Dataset: Characterizing the Accessibility Gap in Computer Use Agents", "comment": "25 pages, 10 figures. Proceedings of the 2026 CHI Conference on Human Factors in Computing Systems (CHI '26)", "summary": "Computer Use Agents (CUAs) operate interfaces by pointing, clicking, and typing -- mirroring interactions of sighted users (SUs) who can thus monitor CUAs and share control. CUAs do not reflect interactions by blind and low-vision users (BLVUs) who use assistive technology (AT). BLVUs thus cannot easily collaborate with CUAs. To characterize the accessibility gap of CUAs, we present A11y-CUA, a dataset of BLVUs and SUs performing 60 everyday tasks with 40.4 hours and 158,325 events. Our dataset analysis reveals that our collected interaction traces quantitatively confirm distinct interaction styles between SU and BLVU groups (mouse- vs. keyboard-dominant) and demonstrate interaction diversity within each group (sequential vs. shortcut navigation for BLVUs). We then compare collected traces to state-of-the-art CUAs under default and AT conditions (keyboard-only, magnifier). The default CUA executed 78.3% of tasks successfully. But with the AT conditions, CUA's performance dropped to 41.67% and 28.3% with keyboard-only and magnifier conditions respectively, and did not reflect nuances of real AT use. With our open A11y-CUA dataset, we aim to promote collaborative and accessible CUAs for everyone."}
{"id": "2602.09347", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09347", "abs": "https://arxiv.org/abs/2602.09347", "authors": ["Jana G. Delfino", "Jason L. Granstedt", "Frank W. Samuelson", "Robert Ochs", "Krishna Juluru"], "title": "Image Quality in the Era of Artificial Intelligence", "comment": "16 pages, 3 figures", "summary": "Artificial intelligence (AI) is being deployed within radiology at a rapid pace. AI has proven an excellent tool for reconstructing and enhancing images that appear sharper, smoother, and more detailed, can be acquired more quickly, and allowing clinicians to review them more rapidly. However, incorporation of AI also introduces new failure modes and can exacerbate the disconnect between perceived quality of an image and information content of that image. Understanding the limitations of AI-enabled image reconstruction and enhancement is critical for safe and effective use of the technology. Hence, the purpose of this communication is to bring awareness to limitations when AI is used to reconstruct or enhance a radiological image, with the goal of enabling users to reap benefits of the technology while minimizing risks."}
{"id": "2602.09744", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.09744", "abs": "https://arxiv.org/abs/2602.09744", "authors": ["Jie Jiang", "Yang Wu", "Qian Li", "Yuling Xiong", "Yihang Su", "Junbang Huo", "Longfei Lu", "Jun Zhang", "Huan Yu"], "title": "DiffuReason: Bridging Latent Reasoning and Generative Refinement for Sequential Recommendation", "comment": null, "summary": "Latent reasoning has emerged as a promising paradigm for sequential recommendation, enabling models to capture complex user intent through multi-step deliberation. Yet existing approaches often rely on deterministic latent chains that accumulate noise and overlook the uncertainty inherent in user intent, and they are typically trained in staged pipelines that hinder joint optimization and exploration. To address these challenges, we propose DiffuReason, a unified \"Think-then-Diffuse\" framework for sequential recommendation. It integrates multi-step Thinking Tokens for latent reasoning, diffusion-based refinement for denoising intermediate representations, and end-to-end Group Relative Policy Optimization (GRPO) alignment to optimize for ranking performance. In the Think stage, the model generates Thinking Tokens that reason over user history to form an initial intent hypothesis. In the Diffuse stage, rather than treating this hypothesis as the final output, we refine it through a diffusion process that models user intent as a probabilistic distribution, providing iterative denoising against reasoning noise. Finally, GRPO-based reinforcement learning enables the reasoning and refinement modules to co-evolve throughout training, without the constraints of staged optimization. Extensive experiments on four benchmarks demonstrate that DiffuReason consistently improves diverse backbone architectures. Online A/B tests on a large-scale industrial platform further validate its practical effectiveness."}
{"id": "2602.09353", "categories": ["cs.HC", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.09353", "abs": "https://arxiv.org/abs/2602.09353", "authors": ["Tuan-He Lee", "Gilly Leshed"], "title": "Understanding Remote Mental Health Supporters' Help-Seeking in Online Communities", "comment": "accepted to CHI'26", "summary": "Providing mental health support for loved ones across a geographic distance creates unique challenges for the remote caregivers, who sometimes turn to online communities for peer support. We qualitatively analyzed 522 Reddit threads to understand what drives remote caregivers' online help-seeking behaviors and the responses they receive from the community. Their purposes of posting included requesting guidance, expressing emotions, and seeking validation. Community responses included providing emotional support, suggesting informational strategies, and sharing personal experiences. While certain themes in posts (emotional toll, monitoring symptoms, and prioritizing caregiver well-being) are shared across remote and non-remote contexts, remote caregivers' posts surfaced nuanced experiences. For example, they often rely on digital cues, such as voice, to interpret care receivers' well-being while struggling with digital silence during crises. We discuss the need for supporting communication and information sharing between remote caregivers and receivers, care coordination for crisis management, and design recommendations for caregiver communities."}
{"id": "2602.09443", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09443", "abs": "https://arxiv.org/abs/2602.09443", "authors": ["Yun Luo", "Futing Wang", "Qianjia Cheng", "Fangchen Yu", "Haodi Lei", "Jianhao Yan", "Chenxi Li", "Jiacheng Chen", "Yufeng Zhao", "Haiyuan Wan", "Yuchen Zhang", "Shenghe Zheng", "Junchi Yao", "Qingyang Zhang", "Haonan He", "Wenxuan Zeng", "Li Sheng", "Chengxing Xie", "Yuxin Zuo", "Yizhuo Li", "Yulun Wu", "Rui Huang", "Dongzhan Zhou", "Kai Chen", "Yu Qiao", "Lei Bai", "Yu Cheng", "Ning Ding", "Bowen Zhou", "Peng Ye", "Ganqu Cui"], "title": "P1-VL: Bridging Visual Perception and Scientific Reasoning in Physics Olympiads", "comment": null, "summary": "The transition from symbolic manipulation to science-grade reasoning represents a pivotal frontier for Large Language Models (LLMs), with physics serving as the critical test anchor for binding abstract logic to physical reality. Physics demands that a model maintain physical consistency with the laws governing the universe, a task that fundamentally requires multimodal perception to ground abstract logic in reality. At the Olympiad level, diagrams are often constitutive rather than illustrative, containing essential constraints, such as boundary conditions and spatial symmetries, that are absent from the text. To bridge this visual-logical gap, we introduce P1-VL, a family of open-source vision-language models engineered for advanced scientific reasoning. Our method harmonizes Curriculum Reinforcement Learning, which employs progressive difficulty expansion to stabilize post-training, with Agentic Augmentation, enabling iterative self-verification at inference. Evaluated on HiPhO, a rigorous benchmark of 13 exams from 2024-2025, our flagship P1-VL-235B-A22B becomes the first open-source Vision-Language Model (VLM) to secure 12 gold medals and achieves the state-of-the-art performance in the open-source models. Our agent-augmented system achieves the No.2 overall rank globally, trailing only Gemini-3-Pro. Beyond physics, P1-VL demonstrates remarkable scientific reasoning capacity and generalizability, establishing significant leads over base models in STEM benchmarks. By open-sourcing P1-VL, we provide a foundational step toward general-purpose physical intelligence to better align visual perceptions with abstract physical laws for machine scientific discovery."}
{"id": "2602.09829", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.09829", "abs": "https://arxiv.org/abs/2602.09829", "authors": ["Yang Wu", "Haoze Wang", "Qian Li", "Jun Zhang", "Huan Yu", "Jie Jiang"], "title": "Internalizing Multi-Agent Reasoning for Accurate and Efficient LLM-based Recommendation", "comment": null, "summary": "Large Language Models (LLMs) are reshaping recommender systems by leveraging extensive world knowledge and semantic reasoning to interpret user intent. However, effectively integrating these capabilities with collaborative signals while avoiding prohibitive inference latency remains a critical bottleneck. To address this, we propose a trajectory-driven internalization framework to develop a Single-agent Trajectory-Aligned Recommender (STAR). Specifically, to internalize complex reasoning capabilities into a single efficient model, we first design a multi-agent teacher system capable of multi-turn tool usage and reflection. This teacher utilizes a Collaborative Signal Translation mechanism to explicitly convert latent behavioral patterns into descriptive natural language evidence to enhance reasoning accuracy. Subsequently, a trajectory-driven distillation pipeline transfers this agentic logic, including planning, tool usage, and self-reflection, into the compact STAR model. Extensive experiments demonstrate that STAR surpasses its teacher by 8.7% to 39.5% while eliminating iterative latency, paving the way for real-time, reasoning-enhanced recommendation."}
{"id": "2602.09381", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.09381", "abs": "https://arxiv.org/abs/2602.09381", "authors": ["Zihao Zhu", "Junnan Yu", "Yuhan Luo"], "title": "Scaffolding Metacognition with GenAI: Exploring Design Opportunities to Support Task Management for University Students with ADHD", "comment": "17 pages excluding reference and appendix. To appear in the Proceedings of the 2026 CHI Conference on Human Factors in Computing Systems (CHI '26)", "summary": "For university students transitioning to an independent and flexible lifestyle, having ADHD poses multiple challenges to their academic task management, which are closely tied to their metacognitive struggles--difficulties in awareness and regulation of one's own thinking processes. The recently surged Generative AI shows promise to mitigate these gaps with its advanced information understanding and generation capabilities. As an exploratory step, we conducted co-design sessions with 20 university students diagnosed with ADHD, followed by interviews with five experts specialized in ADHD intervention. Adopting a metacognitive lens, we examined participants' ideas on GenAI-based task management support and experts' assessments, which led to three design directions: providing cognitive scaffolding to enhance task and self-awareness, promoting reflective task execution for building metacognitive abilities, and facilitating emotional regulation to sustain task engagement. Drawing on these findings, we discuss opportunities for GenAI to support the metacognitive needs of neurodivergent populations, offering future directions for both research and practice."}
{"id": "2602.09463", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09463", "abs": "https://arxiv.org/abs/2602.09463", "authors": ["Furong Jia", "Ling Dai", "Wenjin Deng", "Fan Zhang", "Chen Hu", "Daxin Jiang", "Yu Liu"], "title": "SpotAgent: Grounding Visual Geo-localization in Large Vision-Language Models through Agentic Reasoning", "comment": null, "summary": "Large Vision-Language Models (LVLMs) have demonstrated strong reasoning capabilities in geo-localization, yet they often struggle in real-world scenarios where visual cues are sparse, long-tailed, and highly ambiguous. Previous approaches, bound by internal knowledge, often fail to provide verifiable results, yielding confident but ungrounded predictions when faced with confounded evidence. To address these challenges, we propose SpotAgent, a framework that formalizes geo-localization into an agentic reasoning process that leverages expert-level reasoning to synergize visual interpretation with tool-assisted verification. SpotAgent actively explores and verifies visual cues by leveraging external tools (e.g., web search, maps) through a ReAct diagram. We introduce a 3-stage post-training pipeline starting with a Supervised Fine-Tuning (SFT) stage for basic alignment, followed by an Agentic Cold Start phase utilizing high-quality trajectories synthesized via a Multi-Agent framework, aiming to instill tool-calling expertise. Subsequently, the model's reasoning capabilities are refined through Reinforcement Learning. We propose a Spatially-Aware Dynamic Filtering strategy to enhance the efficiency of the RL stage by prioritizing learnable samples based on spatial difficulty. Extensive experiments on standard benchmarks demonstrate that SpotAgent achieves state-of-the-art performance, effectively mitigating hallucinations while delivering precise and verifiable geo-localization."}
{"id": "2602.09901", "categories": ["cs.IR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.09901", "abs": "https://arxiv.org/abs/2602.09901", "authors": ["Jianzhao Huang", "Xiaorui Huang", "Fei Zhao", "Yunpeng Liu", "Hui Zhang", "Fangcheng Shi", "Congfeng Li", "Zechen Sun", "Yi Wu", "Yao Hu", "Yunhan Bai", "Shaosheng Cao"], "title": "QP-OneModel: A Unified Generative LLM for Multi-Task Query Understanding in Xiaohongshu Search", "comment": null, "summary": "Query Processing (QP) bridges user intent and content supply in large-scale Social Network Service (SNS) search engines. Traditional QP systems rely on pipelines of isolated discriminative models (e.g., BERT), suffering from limited semantic understanding and high maintenance overhead. While Large Language Models (LLMs) offer a potential solution, existing approaches often optimize sub-tasks in isolation, neglecting intrinsic semantic synergy and necessitating independent iterations. Moreover, standard generative methods often lack grounding in SNS scenarios, failing to bridge the gap between open-domain corpora and informal SNS linguistic patterns, while struggling to adhere to rigorous business definitions. We present QP-OneModel, a Unified Generative LLM for Multi-Task Query Understanding in the SNS domain. We reformulate heterogeneous sub-tasks into a unified sequence generation paradigm, adopting a progressive three-stage alignment strategy culminating in multi-reward Reinforcement Learning. Furthermore, QP-OneModel generates intent descriptions as a novel high-fidelity semantic signal, effectively augmenting downstream tasks such as query rewriting and ranking. Offline evaluations show QP-OneModel achieves a 7.35% overall gain over discriminative baselines, with significant F1 boosts in NER (+9.01%) and Term Weighting (+9.31%). It also exhibits superior generalization, surpassing a 32B model by 7.60% accuracy on unseen tasks. Fully deployed at Xiaohongshu, online A/B tests confirm its industrial value, optimizing retrieval relevance (DCG) by 0.21% and lifting user retention by 0.044%."}
{"id": "2602.09423", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09423", "abs": "https://arxiv.org/abs/2602.09423", "authors": ["Xuechen Li", "Shuai Zhang", "Nan Cao", "Qing Chen"], "title": "Beyond Input-Output: Rethinking Creativity through Design-by-Analogy in Human-AI Collaboration", "comment": "20 pages, 9 figures. Accepted to the 2026 CHI Conference on Human Factors in Computing Systems", "summary": "While the proliferation of foundation models has significantly boosted individual productivity, it also introduces a potential challenge: the homogenization of creative content. In response, we revisit Design-by-Analogy (DbA), a cognitively grounded approach that fosters novel solutions by mapping inspiration across domains. However, prevailing perspectives often restrict DbA to early ideation or specific data modalities, while reducing AI-driven design to simplified input-output pipelines. Such conceptual limitations inadvertently foster widespread design fixation. To address this, we expand the understanding of DbA by embedding it into the entire creative process, thereby demonstrating its capacity to mitigate such fixation. Through a systematic review of 85 studies, we identify six forms of representation and classify techniques across seven stages of the creative process. We further discuss three major application domains: creative industries, intelligent manufacturing, and education and services, demonstrating DbA's practical relevance. Building on this synthesis, we frame DbA as a mediating technology for human-AI collaboration and outline the potential opportunities and inherent risks for advancing creativity support in HCI and design research."}
{"id": "2602.09485", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09485", "abs": "https://arxiv.org/abs/2602.09485", "authors": ["Yizhi Wang", "Linan Yue", "Min-Ling Zhang"], "title": "Bridging Efficiency and Transparency: Explainable CoT Compression in Multimodal Large Reasoning Models", "comment": null, "summary": "Long chains of thought (Long CoTs) are widely employed in multimodal reasoning models to tackle complex tasks by capturing detailed visual information. However, these Long CoTs are often excessively lengthy and contain redundant reasoning steps, which can hinder inference efficiency. Compressing these long CoTs is a natural solution, yet existing approaches face two major challenges: (1) they may compromise the integrity of visual-textual reasoning by removing essential alignment cues, and (2) the compression process lacks explainability, making it difficult to discern which information is critical. To address these problems, we propose XMCC, an eXplainable Multimodal CoT Compressor that formulates compression as a sequential decision-making process optimized via reinforcement learning. XMCC can effectively shorten reasoning trajectories while preserving key reasoning steps and answer correctness, and simultaneously generates natural-language explanations for its compression decisions. Extensive experiments on representative multimodal reasoning benchmarks demonstrate that XMCC not only reduces reasoning length but also provides explainable explanations, validating its effectiveness."}
{"id": "2602.09935", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.09935", "abs": "https://arxiv.org/abs/2602.09935", "authors": ["VojtÄch VanÄura", "Martin SpiÅ¡Ã¡k", "Rodrigo Alves", "Ladislav PeÅ¡ka"], "title": "Efficient Learning of Sparse Representations from Interactions", "comment": "In the proceedings of the Web Conference (WWW) 2026 (4 pages)", "summary": "Behavioral patterns captured in embeddings learned from interaction data are pivotal across various stages of production recommender systems. However, in the initial retrieval stage, practitioners face an inherent tradeoff between embedding expressiveness and the scalability and latency of serving components, resulting in the need for representations that are both compact and expressive. To address this challenge, we propose a training strategy for learning high-dimensional sparse embedding layers in place of conventional dense ones, balancing efficiency, representational expressiveness, and interpretability. To demonstrate our approach, we modified the production-grade collaborative filtering autoencoder ELSA, achieving up to 10x reduction in embedding size with no loss of recommendation accuracy, and up to 100x reduction with only a 2.5% loss. Moreover, the active embedding dimensions reveal an interpretable inverted-index structure that segments items in a way directly aligned with the model's latent space, thereby enabling integration of segment-level recommendation functionality (e.g., 2D homepage layouts) within the candidate retrieval model itself. Source codes, additional results, as well as a live demo are available at https://github.com/zombak79/compressed_elsa"}
{"id": "2602.09496", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.09496", "abs": "https://arxiv.org/abs/2602.09496", "authors": ["Yate Ge", "Lin Tian", "Chiqian Xu", "Luyao Xu", "Meiying Li", "Yuanda Hu", "Weiwei Guo"], "title": "Jokeasy: Exploring Human-AI Collaboration in Thematic Joke Generation", "comment": "Accepted at IASDR 2025. This is the author-accepted version. Correspondence to first author: geyate@gmail.com", "summary": "Thematic jokes are central to stand-up comedy, sitcoms, and public speaking, where contexts and punchlines rely on fresh material - news, anecdotes, and cultural references that resonate with the audience. Recent advances in Large Language Models (LLMs) have enabled interactive joke generation through conversational interfaces. Although LLMs enable interactive joke generation, ordinary conversational interfaces seldom give creators enough agency, control, or timely access to such source material for constructing context and punchlines. We designed Jokeasy, a search-enabled prototype system that integrates a dual-role LLM agent acting as both a material scout and a prototype writer to support human-AI collaboration in thematic joke writing. Jokeasy provides a visual canvas in which retrieved web content is organized into editable inspiration blocks and developed through a multistage workflow. A qualitative study with 13 hobbyists and 5 expert participants (including professional comedians and HCI/AI specialists) showed that weaving real-time web material into this structured workflow enriches ideation and preserves author agency, while also revealing needs for finer search control, tighter chat-canvas integration, and more flexible visual editing. These insights refine our understanding of AI-assisted humour writing and guide future creative-writing tools."}
{"id": "2602.09489", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09489", "abs": "https://arxiv.org/abs/2602.09489", "authors": ["Lars Henry Berge Olsen", "Dennis Christensen"], "title": "Computing Conditional Shapley Values Using Tabular Foundation Models", "comment": null, "summary": "Shapley values have become a cornerstone of explainable AI, but they are computationally expensive to use, especially when features are dependent. Evaluating them requires approximating a large number of conditional expectations, either via Monte Carlo integration or regression. Until recently it has not been possible to fully exploit deep learning for the regression approach, because retraining for each conditional expectation takes too long. Tabular foundation models such as TabPFN overcome this computational hurdle by leveraging in-context learning, so each conditional expectation can be approximated without any re-training. In this paper, we compute Shapley values with multiple variants of TabPFN and compare their performance with state-of-the-art methods on both simulated and real datasets. In most cases, TabPFN yields the best performance; where it does not, it is only marginally worse than the best method, at a fraction of the runtime. We discuss further improvements and how tabular foundation models can be better adapted specifically for conditional Shapley value estimation."}
{"id": "2602.10016", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.10016", "abs": "https://arxiv.org/abs/2602.10016", "authors": ["Bojian Hou", "Xiaolong Liu", "Xiaoyi Liu", "Jiaqi Xu", "Yasmine Badr", "Mengyue Hang", "Sudhanshu Chanpuriya", "Junqing Zhou", "Yuhang Yang", "Han Xu", "Qiuling Suo", "Laming Chen", "Yuxi Hu", "Jiasheng Zhang", "Huaqing Xiong", "Yuzhen Huang", "Chao Chen", "Yue Dong", "Yi Yang", "Shuo Chang", "Xiaorui Gan", "Wenlin Chen", "Santanu Kolay", "Darren Liu", "Jade Nie", "Chunzhi Yang", "Jiyan Yang", "Huayu Li"], "title": "Kunlun: Establishing Scaling Laws for Massive-Scale Recommendation Systems through Unified Architecture Design", "comment": "10 pages, 4 figures", "summary": "Deriving predictable scaling laws that govern the relationship between model performance and computational investment is crucial for designing and allocating resources in massive-scale recommendation systems. While such laws are established for large language models, they remain challenging for recommendation systems, especially those processing both user history and context features. We identify poor scaling efficiency as the main barrier to predictable power-law scaling, stemming from inefficient modules with low Model FLOPs Utilization (MFU) and suboptimal resource allocation. We introduce Kunlun, a scalable architecture that systematically improves model efficiency and resource allocation. Our low-level optimizations include Generalized Dot-Product Attention (GDPA), Hierarchical Seed Pooling (HSP), and Sliding Window Attention. Our high-level innovations feature Computation Skip (CompSkip) and Event-level Personalization. These advances increase MFU from 17% to 37% on NVIDIA B200 GPUs and double scaling efficiency over state-of-the-art methods. Kunlun is now deployed in major Meta Ads models, delivering significant production impact."}
{"id": "2602.09522", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.09522", "abs": "https://arxiv.org/abs/2602.09522", "authors": ["Jun Fang", "Ka I Chan", "Xiyuxing Zhang", "Yuntao Wang", "Mingze Gao", "Leyi Peng", "Jiajin Li", "Zihang Zhan", "Zhixin Zhao", "Yuanchun Shi"], "title": "Earinter: A Closed-Loop System for Eating Pace Regulation with Just-in-Time Intervention Using Commodity Earbuds", "comment": null, "summary": "Rapid eating is common yet difficult to regulate in situ, partly because people seldom notice pace changes and sustained self-monitoring is effortful. We present Earinter, a commodity-earbud-based closed-loop system that integrates in-the-wild sensing, real-time reasoning, and theory-grounded just-in-time (JIT) intervention to regulate eating pace during daily meals. Earinter repurposes the earbud's bone-conduction voice sensor to capture chewing-related vibrations and estimate eating pace as chews per swallow (CPS) for on-device inference. With data collected equally across in-lab and in-the-wild sessions, Earinter achieves reliable chewing detection (F1 = 0.97) and accurate eating pace estimation (MAE: 0.18 $\\pm$ 0.13 chews/min, 3.65 $\\pm$ 3.86 chews/swallow), enabling robust tracking for closed-loop use. Guided by Dual Systems Theory and refined through two Wizard-of-Oz pilots, Earinter adopts a user-friendly design for JIT intervention content and delivery policy in daily meals. In a 13-day within-subject field study (N=14), the closed-loop system significantly increased CPS and reduced food-consumption speed, with statistical signs of carryover on retention-probe days and acceptable user burden. Our findings highlight how single-modality commodity earables can support practical, theory-driven closed-loop JIT interventions for regulating eating pace in the wild."}
{"id": "2602.09533", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09533", "abs": "https://arxiv.org/abs/2602.09533", "authors": ["Masanari Oi", "Mahiro Ukai", "Masahiro Kaneko", "Naoaki Okazaki", "Nakamasa Inoue"], "title": "Autoregressive Direct Preference Optimization", "comment": null, "summary": "Direct preference optimization (DPO) has emerged as a promising approach for aligning large language models (LLMs) with human preferences. However, the widespread reliance on the response-level Bradley-Terry (BT) model may limit its full potential, as the reference and learnable models are assumed to be autoregressive only after deriving the objective function. Motivated by this limitation, we revisit the theoretical foundations of DPO and propose a novel formulation that explicitly introduces the autoregressive assumption prior to applying the BT model. By reformulating and extending DPO, we derive a novel variant, termed Autoregressive DPO (ADPO), that explicitly integrates autoregressive modeling into the preference optimization framework. Without violating the theoretical foundations, the derived loss takes an elegant form: it shifts the summation operation in the DPO objective outside the log-sigmoid function. Furthermore, through theoretical analysis of ADPO, we show that there exist two length measures to be considered when designing DPO-based algorithms: the token length $Î¼$ and the feedback length $Î¼$'. To the best of our knowledge, we are the first to explicitly distinguish these two measures and analyze their implications for preference optimization in LLMs."}
{"id": "2602.10024", "categories": ["cs.IR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.10024", "abs": "https://arxiv.org/abs/2602.10024", "authors": ["Dawn Lawrie", "Sean MacAvaney", "James Mayfield", "Luca Soldaini", "Eugene Yang", "Andrew Yates"], "title": "Overview of the TREC 2025 RAGTIME Track", "comment": "10 pages, 3 figures, notebook version of the RAGTIME 2025 overview paper", "summary": "The principal goal of the RAG TREC Instrument for Multilingual Evaluation (RAGTIME) track at TREC is to study report generation from multilingual source documents. The track has created a document collection containing Arabic, Chinese, English, and Russian news stories. RAGTIME includes three task types: Multilingual Report Generation, English Report Generation, and Multilingual Information Retrieval (MLIR). A total of 125 runs were submitted by 13 participating teams (and as baselines by the track coordinators) for three tasks. This overview describes these three tasks and presents the available results."}
{"id": "2602.09631", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.09631", "abs": "https://arxiv.org/abs/2602.09631", "authors": ["Gabriela Molina LeÃ³n", "Benjamin Bach", "Matheus Valentim", "Niklas Elmqvist"], "title": "A Multiliteracy Model for Interactive Visualization Literacy: Definitions, Literacies, and Steps for Future Research", "comment": "Conditionally accepted to CHI 2026", "summary": "This paper presents a theoretical model for interactive visualization literacy to describe how people use interactive data visualizations and systems. Literacies have become an important concept in describing modern life skills, with visualization literacy generally referring to the use and interpretation of data visualizations. However, prior work on visualization literacy overlooks interaction and its associated challenges, despite it being an intrinsic aspect of using visualizations. Based on existing theoretical frameworks, we derive a two-dimensional model that combines four well-known literacies with five novel ones. We found evidence for our model through analyzing existing visualization systems as well as through observations from an exploratory study involving such systems. We conclude by outlining steps towards measuring, evaluating, designing for, and teaching interactive visualization literacy."}
{"id": "2602.09597", "categories": ["cs.AI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2602.09597", "abs": "https://arxiv.org/abs/2602.09597", "authors": ["Martin Bauw"], "title": "Detecting radar targets swarms in range profiles with a partially complex-valued neural network", "comment": null, "summary": "Correctly detecting radar targets is usually challenged by clutter and waveform distortion. An additional difficulty stems from the relative proximity of several targets, the latter being perceived as a single target in the worst case, or influencing each other's detection thresholds. The negative impact of targets proximity notably depends on the range resolution defined by the radar parameters and the adaptive threshold adopted. This paper addresses the matter of targets detection in radar range profiles containing multiple targets with varying proximity and distorted echoes. Inspired by recent contributions in the radar and signal processing literature, this work proposes partially complex-valued neural networks as an adaptive range profile processing. Simulated datasets are generated and experiments are conducted to compare a common pulse compression approach with a simple neural network partially defined by complex-valued parameters. Whereas the pulse compression processes one pulse length at a time, the neural network put forward is a generative architecture going through the entire received signal in one go to generate a complete detection profile."}
{"id": "2602.09163", "categories": ["cs.AI", "cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.09163", "abs": "https://arxiv.org/abs/2602.09163", "authors": ["Xingjian Zhang", "Sophia Moylan", "Ziyang Xiong", "Qiaozhu Mei", "Yichen Luo", "Jiaqi W. Ma"], "title": "FlyAOC: Evaluating Agentic Ontology Curation of Drosophila Scientific Knowledge Bases", "comment": null, "summary": "Scientific knowledge bases accelerate discovery by curating findings from primary literature into structured, queryable formats for both human researchers and emerging AI systems. Maintaining these resources requires expert curators to search relevant papers, reconcile evidence across documents, and produce ontology-grounded annotations - a workflow that existing benchmarks, focused on isolated subtasks like named entity recognition or relation extraction, do not capture. We present FlyBench to evaluate AI agents on end-to-end agentic ontology curation from scientific literature. Given only a gene symbol, agents must search and read from a corpus of 16,898 full-text papers to produce structured annotations: Gene Ontology terms describing function, expression patterns, and historical synonyms linking decades of nomenclature. The benchmark includes 7,397 expert-curated annotations across 100 genes drawn from FlyBase, the Drosophila (fruit fly) knowledge base. We evaluate four baseline agent architectures: memorization, fixed pipeline, single-agent, and multi-agent. We find that architectural choices significantly impact performance, with multi-agent designs outperforming simpler alternatives, yet scaling backbone models yields diminishing returns. All baselines leave substantial room for improvement. Our analysis surfaces several findings to guide future development; for example, agents primarily use retrieval to confirm parametric knowledge rather than discover new information. We hope FlyBench will drive progress on retrieval-augmented scientific reasoning, a capability with broad applications across scientific domains."}
{"id": "2602.09735", "categories": ["cs.HC", "eess.SP"], "pdf": "https://arxiv.org/pdf/2602.09735", "abs": "https://arxiv.org/abs/2602.09735", "authors": ["Bob Van Dyck", "Arne Van Den Kerchove", "Marc M. Van Hulle"], "title": "An open-source implementation of a closed-loop electrocorticographic Brain-Computer Interface using Micromed, FieldTrip, and PsychoPy", "comment": null, "summary": "We present an open-source implementation of a closed-loop Brain-Computer Interface (BCI) system based on electrocorticographic (ECoG) recordings. Our setup integrates FieldTrip for interfacing with a Micromed acquisition system and PsychoPy for implementing experiments. We open-source three custom Python libraries (psychopylib, pymarkerlib, and pyfieldtriplib) each covering different aspects of a closed-loop BCI interface: designing interactive experiments, sending event information, and real-time signal processing. Our modules facilitate the design and operation of a transparent BCI system, promoting customization and flexibility in BCI research, and lowering the barrier for researchers to translate advances in ECoG decoding into BCI applications."}
{"id": "2602.09620", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2602.09620", "abs": "https://arxiv.org/abs/2602.09620", "authors": ["Jorge Fandinno", "Pedro Cabalar", "Philipp Wanko", "Torsten Schaub"], "title": "FLINGO -- Instilling ASP Expressiveness into Linear Integer Constraints", "comment": null, "summary": "Constraint Answer Set Programming (CASP) is a hybrid paradigm that enriches Answer Set Programming (ASP) with numerical constraint processing, something required in many real-world applications. The usual specification of constraints in most CASP solvers is closer to the numerical back-end expressiveness and semantics, rather than to standard specification in ASP. In the latter, numerical attributes are represented with predicates and this allows declaring default values, leaving the attribute undefined, making non-deterministic assignments with choice rules or using aggregated values. In CASP, most (if not all) of these features are lost once we switch to a constraint-based representation of those same attributes. In this paper, we present the FLINGO language (and tool) that incorporates the aforementioned expressiveness inside the numerical constraints and we illustrate its use with several examples. Based on previous work that established its semantic foundations, we also present a translation from the newly introduced FLINGO syntax to regular CASP programs following the CLINGCON input format."}
{"id": "2602.09907", "categories": ["cs.HC", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.09907", "abs": "https://arxiv.org/abs/2602.09907", "authors": ["Yue Fu", "Joel Wester", "Niels Van Berkel", "Alexis Hiniker"], "title": "Self-Regulated Reading with AI Support: An Eight-Week Study with Students", "comment": null, "summary": "College students increasingly use AI chatbots to support academic reading, yet we lack granular understanding of how these interactions shape their reading experience and cognitive engagement. We conducted an eight-week longitudinal study with 15 undergraduates who used AI to support assigned readings in a course. We collected 838 prompts across 239 reading sessions and developed a coding schema categorizing prompts into four cognitive themes: Decoding, Comprehension, Reasoning, and Metacognition. Comprehension prompts dominated (59.6%), with Reasoning (29.8%), Metacognition (8.5%), and Decoding (2.1%) less frequent. Most sessions (72%) contained exactly three prompts, the required minimum of the reading assignment. Within sessions, students showed natural cognitive progression from comprehension toward reasoning, but this progression was truncated. Across eight weeks, students' engagement patterns remained stable, with substantial individual differences persisting throughout. Qualitative analysis revealed an intention-behavior gap: students recognized that effective prompting required effort but rarely applied this knowledge, with efficiency emerging as the primary driver. Students also strategically triaged their engagement based on interest and academic pressures, exhibiting a novel pattern of reading through AI rather than with it: using AI-generated summaries as primary material to filter which sections merited deeper attention. We discuss design implications for AI reading systems that scaffold sustained cognitive engagement."}
{"id": "2602.09653", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09653", "abs": "https://arxiv.org/abs/2602.09653", "authors": ["Shiwei Lyu", "Xidong Wang", "Lei Liu", "Hao Zhu", "Chaohe Zhang", "Jian Wang", "Jinjie Gu", "Benyou Wang", "Yue Shen"], "title": "ClinAlign: Scaling Healthcare Alignment from Clinician Preference", "comment": null, "summary": "Although large language models (LLMs) demonstrate expert-level medical knowledge, aligning their open-ended outputs with fine-grained clinician preferences remains challenging. Existing methods often rely on coarse objectives or unreliable automated judges that are weakly grounded in professional guidelines. We propose a two-stage framework to address this gap. First, we introduce HealthRubrics, a dataset of 7,034 physician-verified preference examples in which clinicians refine LLM-drafted rubrics to meet rigorous medical standards. Second, we distill these rubrics into HealthPrinciples: 119 broadly reusable, clinically grounded principles organized by clinical dimensions, enabling scalable supervision beyond manual annotation. We use HealthPrinciples for (1) offline alignment by synthesizing rubrics for unlabeled queries and (2) an inference-time tool for guided self-revision. A 30B parameter model that activates only 3B parameters at inference trained with our framework achieves 33.4% on HealthBench-Hard, outperforming much larger models including Deepseek-R1 and o3, establishing a resource-efficient baseline for clinical alignment."}
{"id": "2602.10054", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.10054", "abs": "https://arxiv.org/abs/2602.10054", "authors": ["Yang Chen Lin", "Chen-Ying Chen", "Kai-Hsin Hou", "Hung-Yu Chen", "Po-Chih Kuo"], "title": "AIDED: Augmenting Interior Design with Human Experience Data for Designer-AI Co-Design", "comment": "29 pages, 14 figures, Accepted to CHI 2026", "summary": "Interior design often struggles to capture the subtleties of client experience, leaving gaps between what clients feel and what designers can act upon. We present AIDED, a designer-AI co-design workflow that integrates multimodal client data into generative AI (GAI) design processes. In a within-subjects study with twelve professional designers, we compared four modalities: baseline briefs, gaze heatmaps, questionnaire visualizations, and AI-predicted overlays. Results show that questionnaire data were trusted, creativity-enhancing, and satisfying; gaze heatmaps increased cognitive load; and AI-predicted overlays improved GAI communication but required natural language mediation to establish trust. Interviews confirmed that an authenticity-interpretability trade-off is central to balancing client voices with professional control. Our contributions are: (1) a system that incorporates experiential client signals into GAI design workflows; (2) empirical evidence of how different modalities affect design outcomes; and (3) implications for future AI tools that support human-data interaction in creative practice."}
{"id": "2602.09794", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09794", "abs": "https://arxiv.org/abs/2602.09794", "authors": ["Jiaquan Zhang", "Chaoning Zhang", "Shuxu Chen", "Xudong Wang", "Zhenzhen Huang", "Pengcheng Zheng", "Shuai Yuan", "Sheng Zheng", "Qigan Sun", "Jie Zou", "Lik-Hang Lee", "Yang Yang"], "title": "GHS-TDA: A Synergistic Reasoning Framework Integrating Global Hypothesis Space with Topological Data Analysis", "comment": "23pages", "summary": "Chain-of-Thought (CoT) has been shown to significantly improve the reasoning accuracy of large language models (LLMs) on complex tasks. However, due to the autoregressive, step-by-step generation paradigm, existing CoT methods suffer from two fundamental limitations. First, the reasoning process is highly sensitive to early decisions: once an initial error is introduced, it tends to propagate and amplify through subsequent steps, while the lack of a global coordination and revision mechanism makes such errors difficult to correct, ultimately leading to distorted reasoning chains. Second, current CoT approaches lack structured analysis techniques for filtering redundant reasoning and extracting key reasoning features, resulting in unstable reasoning processes and limited interpretability. To address these issues, we propose GHS-TDA. GHS-TDA first constructs a semantically enriched global hypothesis graph to aggregate, align, and coordinate multiple candidate reasoning paths, thereby providing alternative global correction routes when local reasoning fails. It then applies topological data analysis based on persistent homology to capture stable multi-scale structures, remove redundancy and inconsistencies, and extract a more reliable reasoning skeleton. By jointly leveraging reasoning diversity and topological stability, GHS-TDA achieves self-adaptive convergence, produces high-confidence and interpretable reasoning paths, and consistently outperforms strong baselines in terms of both accuracy and robustness across multiple reasoning benchmarks."}
{"id": "2602.09286", "categories": ["cs.AI", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.09286", "abs": "https://arxiv.org/abs/2602.09286", "authors": ["Hanjing Shi", "Dominic DiFranzo"], "title": "Human Control Is the Anchor, Not the Answer: Early Divergence of Oversight in Agentic AI Communities", "comment": null, "summary": "Oversight for agentic AI is often discussed as a single goal (\"human control\"), yet early adoption may produce role-specific expectations. We present a comparative analysis of two newly active Reddit communities in Jan--Feb 2026 that reflect different socio-technical roles: r/OpenClaw (deployment and operations) and r/Moltbook (agent-centered social interaction). We conceptualize this period as an early-stage crystallization phase, where oversight expectations form before norms reach equilibrium.\n  Using topic modeling in a shared comparison space, a coarse-grained oversight-theme abstraction, engagement-weighted salience, and divergence tests, we show the communities are strongly separable (JSD =0.418, cosine =0.372, permutation $p=0.0005$). Across both communities, \"human control\" is an anchor term, but its operational meaning diverges: r/OpenClaw} emphasizes execution guardrails and recovery (action-risk), while r/Moltbook} emphasizes identity, legitimacy, and accountability in public interaction (meaning-risk). The resulting distinction offers a portable lens for designing and evaluating oversight mechanisms that match agent role, rather than applying one-size-fits-all control policies."}
{"id": "2602.09798", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09798", "abs": "https://arxiv.org/abs/2602.09798", "authors": ["Matteo Cardellini", "Enrico Giunchiglia"], "title": "Symbolic Pattern Temporal Numeric Planning with Intermediate Conditions and Effects", "comment": "Under review at the Artificial Intelligence Journal", "summary": "Recently, a Symbolic Pattern Planning (SPP) approach was proposed for numeric planning where a pattern (i.e., a finite sequence of actions) suggests a causal order between actions. The pattern is then encoded in a SMT formula whose models correspond to valid plans. If the suggestion by the pattern is inaccurate and no valid plan can be found, the pattern is extended until it contains the causal order of actions in a valid plan, making the approach complete. In this paper, we extend the SPP approach to the temporal planning with Intermediate Conditions and Effects (ICEs) fragment, where $(i)$ actions are durative (and thus can overlap over time) and have conditions/effects which can be checked/applied at any time during an action's execution, and $(ii)$ one can specify plan's conditions/effects that must be checked/applied at specific times during the plan execution. Experimental results show that our SPP planner Patty $(i)$ outperforms all other planners in the literature in the majority of temporal domains without ICEs, $(ii)$ obtains comparable results with the SoTA search planner for ICS in literature domains with ICEs, and $(iii)$ outperforms the same planner in a novel domain based on a real-world application."}
{"id": "2602.10001", "categories": ["cs.SI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.10001", "abs": "https://arxiv.org/abs/2602.10001", "authors": ["Chenyi Li", "Raja Marjieh", "Haoyu Hu", "Mark Steyvers", "Katherine M. Collins", "Ilia Sucholutsky", "Nori Jacoby"], "title": "Human-AI Synergy Supports Collective Creative Search", "comment": null, "summary": "Generative AI is increasingly transforming creativity into a hybrid human-artificial process, but its impact on the quality and diversity of creative output remains unclear. We study collective creativity using a controlled word-guessing task that balances open-endedness with an objective measure of task performance. Participants attempt to infer a hidden target word, scored based on the semantic similarity of their guesses to the target, while also observing the best guess from previous players. We compare performance and outcome diversity across human-only, AI-only, and hybrid human-AI groups. Hybrid groups achieve the highest performance while preserving high diversity of guesses. Within hybrid groups, both humans and AI agents systematically adjust their strategies relative to single-agent conditions, suggesting higher-order interaction effects, whereby agents adapt to each other's presence. Although some performance benefits can be reproduced through collaboration between heterogeneous AI systems, human-AI collaboration remains superior, underscoring complementary roles in collective creativity."}
{"id": "2602.09802", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.09802", "abs": "https://arxiv.org/abs/2602.09802", "authors": ["Manon Reusens", "Sofie Goethals", "Toon Calders", "David Martens"], "title": "Would a Large Language Model Pay Extra for a View? Inferring Willingness to Pay from Subjective Choices", "comment": null, "summary": "As Large Language Models (LLMs) are increasingly deployed in applications such as travel assistance and purchasing support, they are often required to make subjective choices on behalf of users in settings where no objectively correct answer exists. We study LLM decision-making in a travel-assistant context by presenting models with choice dilemmas and analyzing their responses using multinomial logit models to derive implied willingness to pay (WTP) estimates. These WTP values are subsequently compared to human benchmark values from the economics literature. In addition to a baseline setting, we examine how model behavior changes under more realistic conditions, including the provision of information about users' past choices and persona-based prompting. Our results show that while meaningful WTP values can be derived for larger LLMs, they also display systematic deviations at the attribute level. Additionally, they tend to overestimate human WTP overall, particularly when expensive options or business-oriented personas are introduced. Conditioning models on prior preferences for cheaper options yields valuations that are closer to human benchmarks. Overall, our findings highlight both the potential and the limitations of using LLMs for subjective decision support and underscore the importance of careful model selection, prompt design, and user representation when deploying such systems in practice."}
{"id": "2602.10009", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.10009", "abs": "https://arxiv.org/abs/2602.10009", "authors": ["Sean Memery", "Kartic Subr"], "title": "Discovering High Level Patterns from Simulation Traces", "comment": null, "summary": "Artificial intelligence (AI) agents embedded in environments with physics-based interaction face many challenges including reasoning, planning, summarization, and question answering. This problem is exacerbated when a human user wishes to either guide or interact with the agent in natural language. Although the use of Language Models (LMs) is the default choice, as an AI tool, they struggle with tasks involving physics. The LM's capability for physical reasoning is learned from observational data, rather than being grounded in simulation. A common approach is to include simulation traces as context, but this suffers from poor scalability as simulation traces contain larger volumes of fine-grained numerical and semantic data. In this paper, we propose a natural language guided method to discover coarse-grained patterns (e.g., 'rigid-body collision', 'stable support', etc.) from detailed simulation logs. Specifically, we synthesize programs that operate on simulation logs and map them to a series of high level activated patterns. We show, through two physics benchmarks, that this annotated representation of the simulation log is more amenable to natural language reasoning about physical systems. We demonstrate how this method enables LMs to generate effective reward programs from goals specified in natural language, which may be used within the context of planning or supervised learning."}
{"id": "2602.09813", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09813", "abs": "https://arxiv.org/abs/2602.09813", "authors": ["Dexun Li", "Sidney Tio", "Pradeep Varakantham"], "title": "Efficient Unsupervised Environment Design through Hierarchical Policy Representation Learning", "comment": null, "summary": "Unsupervised Environment Design (UED) has emerged as a promising approach to developing general-purpose agents through automated curriculum generation. Popular UED methods focus on Open-Endedness, where teacher algorithms rely on stochastic processes for infinite generation of useful environments. This assumption becomes impractical in resource-constrained scenarios where teacher-student interaction opportunities are limited. To address this challenge, we introduce a hierarchical Markov Decision Process (MDP) framework for environment design. Our framework features a teacher agent that leverages student policy representations derived from discovered evaluation environments, enabling it to generate training environments based on the student's capabilities. To improve efficiency, we incorporate a generative model that augments the teacher's training dataset with synthetic data, reducing the need for teacher-student interactions. In experiments across several domains, we show that our method outperforms baseline approaches while requiring fewer teacher-student interactions in a single episode. The results suggest the applicability of our approach in settings where training opportunities are limited."}
{"id": "2602.09937", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09937", "abs": "https://arxiv.org/abs/2602.09937", "authors": ["Taeyoon Kim", "Woohyeok Park", "Hoyeong Yun", "Kyungyong Lee"], "title": "Why Do AI Agents Systematically Fail at Cloud Root Cause Analysis?", "comment": null, "summary": "Failures in large-scale cloud systems incur substantial financial losses, making automated Root Cause Analysis (RCA) essential for operational stability. Recent efforts leverage Large Language Model (LLM) agents to automate this task, yet existing systems exhibit low detection accuracy even with capable models, and current evaluation frameworks assess only final answer correctness without revealing why the agent's reasoning failed. This paper presents a process level failure analysis of LLM-based RCA agents. We execute the full OpenRCA benchmark across five LLM models, producing 1,675 agent runs, and classify observed failures into 12 pitfall types across intra-agent reasoning, inter-agent communication, and agent-environment interaction. Our analysis reveals that the most prevalent pitfalls, notably hallucinated data interpretation and incomplete exploration, persist across all models regardless of capability tier, indicating that these failures originate from the shared agent architecture rather than from individual model limitations. Controlled mitigation experiments further show that prompt engineering alone cannot resolve the dominant pitfalls, whereas enriching the inter-agent communication protocol reduces communication-related failures by up to 15 percentage points. The pitfall taxonomy and diagnostic methodology developed in this work provide a foundation for designing more reliable autonomous agents for cloud RCA."}
{"id": "2602.09945", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09945", "abs": "https://arxiv.org/abs/2602.09945", "authors": ["Jinsong Liu", "Yuhang Jiang", "Ramayya Krishnan", "Rema Padman", "Yiye Zhang", "Jiang Bian"], "title": "Closing Reasoning Gaps in Clinical Agents with Differential Reasoning Learning", "comment": null, "summary": "Clinical decision support requires not only correct answers but also clinically valid reasoning. We propose Differential Reasoning Learning (DRL), a framework that improves clinical agents by learning from reasoning discrepancies. From reference reasoning rationales (e.g., physician-authored clinical rationale, clinical guidelines, or outputs from more capable models) and the agent's free-form chain-of-thought (CoT), DRL extracts reasoning graphs as directed acyclic graphs (DAGs) and performs a clinically weighted graph edit distance (GED)-based discrepancy analysis. An LLM-as-a-judge aligns semantically equivalent nodes and diagnoses discrepancies between graphs. These graph-level discrepancy diagnostics are converted into natural-language instructions and stored in a Differential Reasoning Knowledge Base (DR-KB). At inference, we retrieve top-$k$ instructions via Retrieval-Augmented Generation (RAG) to augment the agent prompt and patch likely logic gaps. Evaluation on open medical question answering (QA) benchmarks and a Return Visit Admissions (RVA) prediction task from internal clinical data demonstrates gains over baselines, improving both final-answer accuracy and reasoning fidelity. Ablation studies confirm gains from infusing reference reasoning rationales and the top-$k$ retrieval strategy. Clinicians' review of the output provides further assurance of the approach. Together, results suggest that DRL supports more reliable clinical decision-making in complex reasoning scenarios and offers a practical mechanism for deployment under limited token budgets."}
{"id": "2602.10004", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.10004", "abs": "https://arxiv.org/abs/2602.10004", "authors": ["Junda Wang", "Zhichao Yang", "Dongxu Zhang", "Sanjit Singh Batra", "Robert E. Tillman"], "title": "ESTAR: Early-Stopping Token-Aware Reasoning For Efficient Inference", "comment": null, "summary": "Large reasoning models (LRMs) achieve state-of-the-art performance by generating long chains-of-thought, but often waste computation on redundant reasoning after the correct answer has already been reached. We introduce Early-Stopping for Token-Aware Reasoning (ESTAR), which detects and reduces such reasoning redundancy to improve efficiency without sacrificing accuracy. Our method combines (i) a trajectory-based classifier that identifies when reasoning can be safely stopped, (ii) supervised fine-tuning to teach LRMs to propose self-generated <stop> signals, and (iii) <stop>-aware reinforcement learning that truncates rollouts at self-generated stop points with compute-aware rewards. Experiments on four reasoning datasets show that ESTAR reduces reasoning length by about 3.7x (from 4,799 to 1,290) while preserving accuracy (74.9% vs. 74.2%), with strong cross-domain generalization. These results highlight early stopping as a simple yet powerful mechanism for improving reasoning efficiency in LRMs."}
{"id": "2602.10009", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.10009", "abs": "https://arxiv.org/abs/2602.10009", "authors": ["Sean Memery", "Kartic Subr"], "title": "Discovering High Level Patterns from Simulation Traces", "comment": null, "summary": "Artificial intelligence (AI) agents embedded in environments with physics-based interaction face many challenges including reasoning, planning, summarization, and question answering. This problem is exacerbated when a human user wishes to either guide or interact with the agent in natural language. Although the use of Language Models (LMs) is the default choice, as an AI tool, they struggle with tasks involving physics. The LM's capability for physical reasoning is learned from observational data, rather than being grounded in simulation. A common approach is to include simulation traces as context, but this suffers from poor scalability as simulation traces contain larger volumes of fine-grained numerical and semantic data. In this paper, we propose a natural language guided method to discover coarse-grained patterns (e.g., 'rigid-body collision', 'stable support', etc.) from detailed simulation logs. Specifically, we synthesize programs that operate on simulation logs and map them to a series of high level activated patterns. We show, through two physics benchmarks, that this annotated representation of the simulation log is more amenable to natural language reasoning about physical systems. We demonstrate how this method enables LMs to generate effective reward programs from goals specified in natural language, which may be used within the context of planning or supervised learning."}
{"id": "2602.10063", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.10063", "abs": "https://arxiv.org/abs/2602.10063", "authors": ["Tianyi Jiang", "Arctanx An", "Hengyi Feng", "Naixin Zhai", "Haodong Li", "Xiaomin Yu", "Jiahui Liu", "Hanwen Du", "Shuo Zhang", "Zhi Yang", "Jie Huang", "Yuhua Li", "Yongxin Ni", "Huacan Wang", "Ronghao Chen"], "title": "Chain of Mindset: Reasoning with Adaptive Cognitive Modes", "comment": null, "summary": "Human problem-solving is never the repetition of a single mindset, by which we mean a distinct mode of cognitive processing. When tackling a specific task, we do not rely on a single mindset; instead, we integrate multiple mindsets within the single solution process. However, existing LLM reasoning methods fall into a common trap: they apply the same fixed mindset across all steps, overlooking that different stages of solving the same problem require fundamentally different mindsets. This single-minded assumption prevents models from reaching the next level of intelligence. To address this limitation, we propose Chain of Mindset (CoM), a training-free agentic framework that enables step-level adaptive mindset orchestration. CoM decomposes reasoning into four functionally heterogeneous mindsets: Spatial, Convergent, Divergent, and Algorithmic. A Meta-Agent dynamically selects the optimal mindset based on the evolving reasoning state, while a bidirectional Context Gate filters cross-module information flow to maintain effectiveness and efficiency. Experiments across six challenging benchmarks spanning mathematics, code generation, scientific QA, and spatial reasoning demonstrate that CoM achieves state-of-the-art performance, outperforming the strongest baseline by 4.96\\% and 4.72\\% in overall accuracy on Qwen3-VL-32B-Instruct and Gemini-2.0-Flash, while balancing reasoning efficiency. Our code is publicly available at \\href{https://github.com/QuantaAlpha/chain-of-mindset}{https://github.com/QuantaAlpha/chain-of-mindset}."}
{"id": "2602.10085", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.10085", "abs": "https://arxiv.org/abs/2602.10085", "authors": ["Richard Bornemann", "Pierluigi Vito Amadori", "Antoine Cully"], "title": "CODE-SHARP: Continuous Open-ended Discovery and Evolution of Skills as Hierarchical Reward Programs", "comment": "Preprint", "summary": "Developing agents capable of open-endedly discovering and learning novel skills is a grand challenge in Artificial Intelligence. While reinforcement learning offers a powerful framework for training agents to master complex skills, it typically relies on hand-designed reward functions. This is infeasible for open-ended skill discovery, where the set of meaningful skills is not known a priori. While recent methods have shown promising results towards automating reward function design, they remain limited to refining rewards for pre-defined tasks. To address this limitation, we introduce Continuous Open-ended Discovery and Evolution of Skills as Hierarchical Reward Programs (CODE-SHARP), a novel framework leveraging Foundation Models (FM) to open-endedly expand and refine a hierarchical skill archive, structured as a directed graph of executable reward functions in code. We show that a goal-conditioned agent trained exclusively on the rewards generated by the discovered SHARP skills learns to solve increasingly long-horizon goals in the Craftax environment. When composed by a high-level FM-based planner, the discovered skills enable a single goal-conditioned agent to solve complex, long-horizon tasks, outperforming both pretrained agents and task-specific expert policies by over $134$% on average. We will open-source our code and provide additional videos $\\href{https://sites.google.com/view/code-sharp/homepage}{here}$."}
{"id": "2602.10090", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.10090", "abs": "https://arxiv.org/abs/2602.10090", "authors": ["Zhaoyang Wang", "Canwen Xu", "Boyi Liu", "Yite Wang", "Siwei Han", "Zhewei Yao", "Huaxiu Yao", "Yuxiong He"], "title": "Agent World Model: Infinity Synthetic Environments for Agentic Reinforcement Learning", "comment": "41 pages", "summary": "Recent advances in large language model (LLM) have empowered autonomous agents to perform complex tasks that require multi-turn interactions with tools and environments. However, scaling such agent training is limited by the lack of diverse and reliable environments. In this paper, we propose Agent World Model (AWM), a fully synthetic environment generation pipeline. Using this pipeline, we scale to 1,000 environments covering everyday scenarios, in which agents can interact with rich toolsets (35 tools per environment on average) and obtain high-quality observations. Notably, these environments are code-driven and backed by databases, providing more reliable and consistent state transitions than environments simulated by LLMs. Moreover, they enable more efficient agent interaction compared with collecting trajectories from realistic environments. To demonstrate the effectiveness of this resource, we perform large-scale reinforcement learning for multi-turn tool-use agents. Thanks to the fully executable environments and accessible database states, we can also design reliable reward functions. Experiments on three benchmarks show that training exclusively in synthetic environments, rather than benchmark-specific ones, yields strong out-of-distribution generalization. The code is available at https://github.com/Snowflake-Labs/agent-world-model."}
{"id": "2602.09423", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09423", "abs": "https://arxiv.org/abs/2602.09423", "authors": ["Xuechen Li", "Shuai Zhang", "Nan Cao", "Qing Chen"], "title": "Beyond Input-Output: Rethinking Creativity through Design-by-Analogy in Human-AI Collaboration", "comment": "20 pages, 9 figures. Accepted to the 2026 CHI Conference on Human Factors in Computing Systems", "summary": "While the proliferation of foundation models has significantly boosted individual productivity, it also introduces a potential challenge: the homogenization of creative content. In response, we revisit Design-by-Analogy (DbA), a cognitively grounded approach that fosters novel solutions by mapping inspiration across domains. However, prevailing perspectives often restrict DbA to early ideation or specific data modalities, while reducing AI-driven design to simplified input-output pipelines. Such conceptual limitations inadvertently foster widespread design fixation. To address this, we expand the understanding of DbA by embedding it into the entire creative process, thereby demonstrating its capacity to mitigate such fixation. Through a systematic review of 85 studies, we identify six forms of representation and classify techniques across seven stages of the creative process. We further discuss three major application domains: creative industries, intelligent manufacturing, and education and services, demonstrating DbA's practical relevance. Building on this synthesis, we frame DbA as a mediating technology for human-AI collaboration and outline the potential opportunities and inherent risks for advancing creativity support in HCI and design research."}
{"id": "2602.09616", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09616", "abs": "https://arxiv.org/abs/2602.09616", "authors": ["Zeinab Sadat Taghavi", "Ali Modarressi", "Hinrich Schutze", "Andreas Marfurt"], "title": "With Argus Eyes: Assessing Retrieval Gaps via Uncertainty Scoring to Detect and Remedy Retrieval Blind Spots", "comment": "8 pages", "summary": "Reliable retrieval-augmented generation (RAG) systems depend fundamentally on the retriever's ability to find relevant information. We show that neural retrievers used in RAG systems have blind spots, which we define as the failure to retrieve entities that are relevant to the query, but have low similarity to the query embedding. We investigate the training-induced biases that cause such blind spot entities to be mapped to inaccessible parts of the embedding space, resulting in low retrievability. Using a large-scale dataset constructed from Wikidata relations and first paragraphs of Wikipedia, and our proposed Retrieval Probability Score (RPS), we show that blind spot risk in standard retrievers (e.g., CONTRIEVER, REASONIR) can be predicted pre-index from entity embedding geometry, avoiding expensive retrieval evaluations. To address these blind spots, we introduce ARGUS, a pipeline that enables the retrievability of high-risk (low-RPS) entities through targeted document augmentation from a knowledge base (KB), first paragraphs of Wikipedia, in our case. Extensive experiments on BRIGHT, IMPLIRET, and RAR-B show that ARGUS achieves consistent improvements across all evaluated retrievers (averaging +3.4 nDCG@5 and +4.5 nDCG@10 absolute points), with substantially larger gains in challenging subsets. These results establish that preemptively remedying blind spots is critical for building robust and trustworthy RAG systems (Code and Data)."}
{"id": "2602.09907", "categories": ["cs.HC", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.09907", "abs": "https://arxiv.org/abs/2602.09907", "authors": ["Yue Fu", "Joel Wester", "Niels Van Berkel", "Alexis Hiniker"], "title": "Self-Regulated Reading with AI Support: An Eight-Week Study with Students", "comment": null, "summary": "College students increasingly use AI chatbots to support academic reading, yet we lack granular understanding of how these interactions shape their reading experience and cognitive engagement. We conducted an eight-week longitudinal study with 15 undergraduates who used AI to support assigned readings in a course. We collected 838 prompts across 239 reading sessions and developed a coding schema categorizing prompts into four cognitive themes: Decoding, Comprehension, Reasoning, and Metacognition. Comprehension prompts dominated (59.6%), with Reasoning (29.8%), Metacognition (8.5%), and Decoding (2.1%) less frequent. Most sessions (72%) contained exactly three prompts, the required minimum of the reading assignment. Within sessions, students showed natural cognitive progression from comprehension toward reasoning, but this progression was truncated. Across eight weeks, students' engagement patterns remained stable, with substantial individual differences persisting throughout. Qualitative analysis revealed an intention-behavior gap: students recognized that effective prompting required effort but rarely applied this knowledge, with efficiency emerging as the primary driver. Students also strategically triaged their engagement based on interest and academic pressures, exhibiting a novel pattern of reading through AI rather than with it: using AI-generated summaries as primary material to filter which sections merited deeper attention. We discuss design implications for AI reading systems that scaffold sustained cognitive engagement."}
{"id": "2602.10016", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.10016", "abs": "https://arxiv.org/abs/2602.10016", "authors": ["Bojian Hou", "Xiaolong Liu", "Xiaoyi Liu", "Jiaqi Xu", "Yasmine Badr", "Mengyue Hang", "Sudhanshu Chanpuriya", "Junqing Zhou", "Yuhang Yang", "Han Xu", "Qiuling Suo", "Laming Chen", "Yuxi Hu", "Jiasheng Zhang", "Huaqing Xiong", "Yuzhen Huang", "Chao Chen", "Yue Dong", "Yi Yang", "Shuo Chang", "Xiaorui Gan", "Wenlin Chen", "Santanu Kolay", "Darren Liu", "Jade Nie", "Chunzhi Yang", "Jiyan Yang", "Huayu Li"], "title": "Kunlun: Establishing Scaling Laws for Massive-Scale Recommendation Systems through Unified Architecture Design", "comment": "10 pages, 4 figures", "summary": "Deriving predictable scaling laws that govern the relationship between model performance and computational investment is crucial for designing and allocating resources in massive-scale recommendation systems. While such laws are established for large language models, they remain challenging for recommendation systems, especially those processing both user history and context features. We identify poor scaling efficiency as the main barrier to predictable power-law scaling, stemming from inefficient modules with low Model FLOPs Utilization (MFU) and suboptimal resource allocation. We introduce Kunlun, a scalable architecture that systematically improves model efficiency and resource allocation. Our low-level optimizations include Generalized Dot-Product Attention (GDPA), Hierarchical Seed Pooling (HSP), and Sliding Window Attention. Our high-level innovations feature Computation Skip (CompSkip) and Event-level Personalization. These advances increase MFU from 17% to 37% on NVIDIA B200 GPUs and double scaling efficiency over state-of-the-art methods. Kunlun is now deployed in major Meta Ads models, delivering significant production impact."}
